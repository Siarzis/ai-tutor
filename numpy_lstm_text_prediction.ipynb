{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX4J2HAfFP/LkM3qlDNNnn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "2p96vqoHr57j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v0r7AtR4rvZY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a simple dataset of text sequences"
      ],
      "metadata": {
        "id": "LE7iUrCrr_mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "def generate_dataset(num_words=100, max_word_size=10):\n",
        "\n",
        "    sequences = []\n",
        "\n",
        "    for _ in range (num_words):\n",
        "\n",
        "        random_number =  np.random.randint(1, max_word_size)\n",
        "        sample = ['s'] * random_number + ['t'] * random_number +  ['EOS']\n",
        "        sequences.append(sample)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "num_words=100\n",
        "max_word_size=10\n",
        "\n",
        "vocabulary = generate_dataset(num_words, max_word_size)\n",
        "print(vocabulary[88])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtDSH0h7sEYu",
        "outputId": "349acd6e-c186-4331-8aa6-afe6565b1135"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s', 's', 's', 's', 's', 's', 's', 's', 't', 't', 't', 't', 't', 't', 't', 't', 'EOS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform one-hot encoding on the generated vocabulary"
      ],
      "metadata": {
        "id": "WHjhHgixBqwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_to_dict(vocabulary):\n",
        "\n",
        "    word_to_index = {}\n",
        "    index_to_word = {}\n",
        "\n",
        "    str_vocabulary = [''.join(word) for word in vocabulary]\n",
        "\n",
        "    # remove duplicate words in the dictionary\n",
        "    unique_vocabulary = set(str_vocabulary)\n",
        "    unique_vocabulary = list(unique_vocabulary)\n",
        "\n",
        "    # find the word with the maximum length in the vocabulary\n",
        "    max_word_size = max(unique_vocabulary, key=len)\n",
        "    # compute the maximum word length\n",
        "    max_word_size = int((len(max_word_size) - 3 ) / 2)\n",
        "\n",
        "    # create a diagonal list of lists\n",
        "    encoding = [['0' if i != j else '1' for j in range(max_word_size)] for i in range(max_word_size)]\n",
        "    encoding = [''.join(row) for row in encoding]\n",
        "\n",
        "    for word in unique_vocabulary:\n",
        "\n",
        "        word_length = int((len(word) - 3 ) / 2)\n",
        "        word_to_index[word] = encoding[word_length-1]\n",
        "        index_to_word[encoding[word_length-1]] = word\n",
        "\n",
        "    return word_to_index, index_to_word\n",
        "\n",
        "word_to_index, index_to_word = seq_to_dict(vocabulary)\n",
        "\n",
        "print(word_to_index)\n",
        "print(index_to_word)\n",
        "\n",
        "index_to_word = 1"
      ],
      "metadata": {
        "id": "_87B5ukiBsXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb987f02-6c05-4298-d6f1-f03fda03ead6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ssssttttEOS': '000100000', 'ssssssttttttEOS': '000001000', 'ssttEOS': '010000000', 'ssssssssttttttttEOS': '000000010', 'ssssssstttttttEOS': '000000100', 'stEOS': '100000000', 'ssstttEOS': '001000000', 'ssssssssstttttttttEOS': '000000001', 'ssssstttttEOS': '000010000'}\n",
            "{'000100000': 'ssssttttEOS', '000001000': 'ssssssttttttEOS', '010000000': 'ssttEOS', '000000010': 'ssssssssttttttttEOS', '000000100': 'ssssssstttttttEOS', '100000000': 'stEOS', '001000000': 'ssstttEOS', '000000001': 'ssssssssstttttttttEOS', '000010000': 'ssssstttttEOS'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleSequencesDataset(Dataset):\n",
        "    def __init__(self, data, targets):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        sample = {'data': self.data[id], 'target': self.targets[id]}\n"
      ],
      "metadata": {
        "id": "ArXSUFbSXxWS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialization of the RNN"
      ],
      "metadata": {
        "id": "Apw9WbJArC-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_init(num_hidden_nodes, num_tokens):\n",
        "\n",
        "    # initialize input weight matrix\n",
        "    W_x = np.random.uniform(-1, 1, size=(num_hidden_nodes, num_tokens))\n",
        "\n",
        "    # initialize hidden state weight matrix\n",
        "    W_h = np.zeros((num_hidden_nodes, num_hidden_nodes))\n",
        "\n",
        "    # initialize output weight matrix\n",
        "    W_y = np.random.uniform(-1, 1, size=(num_tokens, num_hidden_nodes))\n",
        "\n",
        "    return W_x, W_h, W_y\n",
        "\n",
        "rnn_init(3, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS_lHAiFrBkt",
        "outputId": "d21e37a2-9140-4714-ec8d-bc0dc833c61a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.33797651,  0.16137324, -0.25543447,  0.88026688],\n",
              "        [ 0.94732767, -0.43215805, -0.38927228, -0.02877249],\n",
              "        [-0.10315171,  0.98891493, -0.64814949, -0.96384927]]),\n",
              " array([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]]),\n",
              " array([[-0.01221257, -0.64235458, -0.26706243],\n",
              "        [ 0.48834105,  0.44187985, -0.38387842],\n",
              "        [ 0.08508046,  0.01762815,  0.27266524],\n",
              "        [-0.49907636,  0.1797417 ,  0.95778572]]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of activation functions"
      ],
      "metadata": {
        "id": "0rkwHVhMEz6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    # calculate the exponential of each element in the array\n",
        "    exp_x = np.exp(x)\n",
        "\n",
        "    # calculate the sum of the exponentials\n",
        "    sum_exp_x = np.sum(exp_x)\n",
        "\n",
        "    # calculate the softmax values by dividing each exponential by the sum of exponentials\n",
        "    softmax_values = exp_x / sum_exp_x\n",
        "\n",
        "    return softmax_values"
      ],
      "metadata": {
        "id": "2AblMZWuE4HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward pass"
      ],
      "metadata": {
        "id": "j0ZRe4qRBeTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rnn_forward_pass():\n",
        "\n",
        "    # calculate hidden nodes (a_t)\n",
        "    a_t = W_h @ h_t_1 + W_x @ x_t\n",
        "\n",
        "    # calculate hidden state\n",
        "    h_t = np.tanh(a_t) # TO CHECK\n",
        "\n",
        "    # calculate RNN output\n",
        "    # softmax maps a given vector to range [0.0, 1.0]. Since we have a one-hot\n",
        "    # encoding representation, we need to find which index of the generated\n",
        "    # output has the largest probability to be predicted\n",
        "    y_t = softmax(W_y @ h_t)"
      ],
      "metadata": {
        "id": "Lyg16gj6CBsL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "N3J_5__AGoeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}